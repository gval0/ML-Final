{"cells":[{"cell_type":"markdown","metadata":{"id":"2h_IMfSBeCP3"},"source":["## PatchTST Model Experiment for Walmart Sales Forecasting\n","Final Project - ML Course\n","\n","This script is written with clear Colab cell/markdown demarcations so that it can be\n","copied into a notebook and executed cell-by-cell."],"id":"2h_IMfSBeCP3"},{"cell_type":"markdown","metadata":{"id":"TDZAOVVIeCP3"},"source":["### CELL 1: Setup and Installations"],"id":"TDZAOVVIeCP3"},{"cell_type":"markdown","metadata":{"id":"UCN8gHmUeCP4"},"source":["Install required packages"],"id":"UCN8gHmUeCP4"},{"cell_type":"code","execution_count":1,"metadata":{"id":"U3b_nvUAeCP4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751870978356,"user_tz":-240,"elapsed":136281,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"ad61431b-02ff-4fec-ad31-74c6743a3110"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.14.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.2 torchmetrics-1.7.4\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting mlflow\n","  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n","Collecting mlflow-skinny==3.1.1 (from mlflow)\n","  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n","Collecting alembic!=1.10.0,<2 (from mlflow)\n","  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting docker<8,>=4.0.0 (from mlflow)\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting graphene<4 (from mlflow)\n","  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n","Collecting gunicorn<24 (from mlflow)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n","Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n","Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n","Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n","  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.14)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n","Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n","  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n","  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (24.2)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.29.5)\n","Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.0)\n","Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.38.0)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n","Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow)\n","  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n","Downloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gunicorn, graphql-core, opentelemetry-api, graphql-relay, docker, alembic, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n","Successfully installed alembic-1.16.2 databricks-sdk-0.57.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.1.1 mlflow-skinny-3.1.1 opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1\n","Collecting dagshub\n","  Downloading dagshub-0.5.10-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\n","Collecting appdirs>=1.4.4 (from dagshub)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.2.1)\n","Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\n","Requirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\n","Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (13.9.4)\n","Collecting dacite~=1.6.0 (from dagshub)\n","  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.5.0)\n","Collecting gql[requests] (from dagshub)\n","  Downloading gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\n","Collecting dataclasses-json (from dagshub)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.2)\n","Collecting treelib>=1.6.4 (from dagshub)\n","  Downloading treelib-1.8.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting pathvalidate>=3.0.0 (from dagshub)\n","  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\n","Collecting boto3 (from dagshub)\n","  Downloading boto3-1.39.3-py3-none-any.whl.metadata (6.6 kB)\n","Collecting semver (from dagshub)\n","  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n","Collecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n","  Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.4.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.2.1)\n","Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (2.11.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (4.14.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.2)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from treelib>=1.6.4->dagshub) (1.17.0)\n","Collecting botocore<1.40.0,>=1.39.3 (from boto3->dagshub)\n","  Downloading botocore-1.39.3-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->dagshub)\n","  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: graphql-core<3.2.7,>=3.2 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (3.2.6)\n","Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.20.1)\n","Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: requests<3,>=2.26 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.40.0,>=1.39.3->boto3->dagshub) (2.4.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (24.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.4.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.2)\n","Downloading dagshub-0.5.10-py3-none-any.whl (260 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n","Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl (33 kB)\n","Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n","Downloading treelib-1.8.0-py3-none-any.whl (30 kB)\n","Downloading boto3-1.39.3-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n","Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading botocore-1.39.3-py3-none-any.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading gql-3.5.3-py2.py3-none-any.whl (74 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: appdirs, treelib, semver, pathvalidate, mypy-extensions, marshmallow, jmespath, dacite, backoff, typing-inspect, gql, botocore, s3transfer, dataclasses-json, dagshub-annotation-converter, boto3, dagshub\n","Successfully installed appdirs-1.4.4 backoff-2.2.1 boto3-1.39.3 botocore-1.39.3 dacite-1.6.0 dagshub-0.5.10 dagshub-annotation-converter-0.1.10 dataclasses-json-0.6.7 gql-3.5.3 jmespath-1.0.1 marshmallow-3.26.1 mypy-extensions-1.1.0 pathvalidate-3.3.1 s3transfer-0.13.0 semver-3.0.4 treelib-1.8.0 typing-inspect-0.9.0\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}],"source":["!pip install einops\n","!pip install pytorch-lightning\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install mlflow\n","!pip install dagshub\n","!pip install joblib\n","!pip install scikit-learn\n","!pip install pandas numpy matplotlib seaborn"],"id":"U3b_nvUAeCP4"},{"cell_type":"markdown","metadata":{"id":"B4sbc_h0eCP4"},"source":["### CELL 2: Mount Google Drive"],"id":"B4sbc_h0eCP4"},{"cell_type":"markdown","metadata":{"id":"BDVYYzMNeCP5"},"source":["Mount Google Drive"],"id":"BDVYYzMNeCP5"},{"cell_type":"code","execution_count":3,"metadata":{"id":"Qi55_GS-eCP5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751871210547,"user_tz":-240,"elapsed":2158,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"8be44d9c-035f-457f-ef57-fcb02ca54281"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/MyDrive/ML-Final')"],"id":"Qi55_GS-eCP5"},{"cell_type":"markdown","metadata":{"id":"3_USTt_heCP5"},"source":["### CELL 3: Import Libraries"],"id":"3_USTt_heCP5"},{"cell_type":"markdown","metadata":{"id":"en7l1CCpeCP6"},"source":["Import required libraries"],"id":"en7l1CCpeCP6"},{"cell_type":"code","execution_count":4,"metadata":{"id":"7-WCXrVjeCP6","executionInfo":{"status":"ok","timestamp":1751871233167,"user_tz":-240,"elapsed":15915,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime, timedelta\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# PyTorch and Deep Learning\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","# Sklearn utilities\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","import joblib\n","\n","# MLflow and experiment tracking\n","import mlflow\n","import mlflow.pytorch\n","import dagshub\n","\n","# System utilities\n","import sys\n","sys.path.append('.')"],"id":"7-WCXrVjeCP6"},{"cell_type":"markdown","metadata":{"id":"gyv-QAZPeCP6"},"source":["### CELL 4: Initialize MLflow and Load Data"],"id":"gyv-QAZPeCP6"},{"cell_type":"markdown","metadata":{"id":"bVVVvwhmeCP6"},"source":["Initialize MLflow experiment tracking"],"id":"bVVVvwhmeCP6"},{"cell_type":"code","execution_count":5,"metadata":{"id":"w9XpwaoQeCP6","colab":{"base_uri":"https://localhost:8080/","height":242,"referenced_widgets":["ec521b6752c2406daa97a81b02565fa4","e1e16669daa84ac2b67f5632da2368be"]},"executionInfo":{"status":"ok","timestamp":1751871258587,"user_tz":-240,"elapsed":4080,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"e3534228-02df-44d8-e98e-61ded83da407"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec521b6752c2406daa97a81b02565fa4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Open the following link in your browser to authorize the client:\n","https://dagshub.com/login/oauth/authorize?state=87c719d9-0324-49b7-954a-e5ac8402552a&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=a47e86de90962382b8d936cec10e0cbb2d4afc9692f2269b869336fa13c8604b\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Accessing as lagorg22\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as lagorg22\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Initialized MLflow to track repo \u001b[32m\"egval20/ML-Final\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"egval20/ML-Final\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Repository egval20/ML-Final initialized!\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository egval20/ML-Final initialized!\n","</pre>\n"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<Experiment: artifact_location='mlflow-artifacts:/e98e1cc06f3a4654b9ba8710a9bb468d', creation_time=1751820253864, experiment_id='9', last_update_time=1751820253864, lifecycle_stage='active', name='PatchTST', tags={}>"]},"metadata":{},"execution_count":5}],"source":["dagshub.init(repo_owner='egval20', repo_name='ML-Final', mlflow=True)\n","mlflow.set_experiment(\"PatchTST\")"],"id":"w9XpwaoQeCP6"},{"cell_type":"markdown","metadata":{"id":"DoaLbPEYeCP6"},"source":["### CELL 5: Load Preprocessing Pipeline and Data"],"id":"DoaLbPEYeCP6"},{"cell_type":"markdown","metadata":{"id":"vtfVnP8BeCP6"},"source":["Load preprocessing pipeline and data"],"id":"vtfVnP8BeCP6"},{"cell_type":"code","execution_count":6,"metadata":{"id":"kzxEmsOfeCP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751871265761,"user_tz":-240,"elapsed":4906,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"6279a744-6bb7-4cc2-ddba-ec49b75822c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading raw data...\n","Train shape: (421570, 5)\n","Test shape: (115064, 4)\n","Date range - Train: 2010-02-05 to 2012-10-26\n","Date range - Test: 2012-11-02 to 2013-07-26\n"]}],"source":["from data_preprocessing_pipeline import *\n","\n","def get_model_ready_data(pipeline_path='preprocessing_pipeline.pkl'):\n","    pipeline = joblib.load(pipeline_path)\n","    def preprocess_for_model(raw_data):\n","        return pipeline.transform(raw_data)\n","    return preprocess_for_model, pipeline\n","\n","# Load preprocessing pipeline\n","preprocess_fn, loaded_pipeline = get_model_ready_data()\n","\n","# Load raw data\n","print(\"Loading raw data...\")\n","train_raw = pd.read_csv('data/train.csv')\n","test_raw = pd.read_csv('data/test.csv')\n","stores = pd.read_csv('data/stores.csv')\n","features = pd.read_csv('data/features.csv')\n","\n","print(f\"Train shape: {train_raw.shape}\")\n","print(f\"Test shape: {test_raw.shape}\")\n","print(f\"Date range - Train: {train_raw['Date'].min()} to {train_raw['Date'].max()}\")\n","print(f\"Date range - Test: {test_raw['Date'].min()} to {test_raw['Date'].max()}\")"],"id":"kzxEmsOfeCP6"},{"cell_type":"markdown","metadata":{"id":"XRjDNUJpeCP7"},"source":["### CELL 6: Apply Preprocessing"],"id":"XRjDNUJpeCP7"},{"cell_type":"markdown","metadata":{"id":"p_wuwVfVeCP7"},"source":["Apply preprocessing pipeline"],"id":"p_wuwVfVeCP7"},{"cell_type":"code","execution_count":7,"metadata":{"id":"k6L3iX1HeCP7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751871284654,"user_tz":-240,"elapsed":13656,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"db67616a-4d0c-4c68-f756-98945df26ac2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dropped 12 lag/MA columns: ['Sales_Lag_1', 'Sales_Lag_2', 'Sales_Lag_3', 'Sales_Lag_4', 'Sales_Lag_8', 'Sales_Lag_52', 'Sales_MA_4', 'Sales_MA_8', 'Sales_MA_12', 'Sales_STD_4', 'Sales_STD_8', 'Sales_STD_12']\n","Dropped 12 lag/MA columns: ['Sales_Lag_1', 'Sales_Lag_2', 'Sales_Lag_3', 'Sales_Lag_4', 'Sales_Lag_8', 'Sales_Lag_52', 'Sales_MA_4', 'Sales_MA_8', 'Sales_MA_12', 'Sales_STD_4', 'Sales_STD_8', 'Sales_STD_12']\n","🏃 View run PatchTST_Cleaning at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9/runs/7b0f4b262b1c4075abdbca6103194cfd\n","🧪 View experiment at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9\n","Cleaned train shape: (421570, 52)\n"]}],"source":["train_processed = preprocess_fn(train_raw)\n","test_processed = preprocess_fn(test_raw)\n","\n","# Drop lag features (same list as ARIMA notebook)\n","lag_columns_to_drop = [\n","    'Sales_Lag_1', 'Sales_Lag_2', 'Sales_Lag_3', 'Sales_Lag_4', 'Sales_Lag_8', 'Sales_Lag_52',\n","    'Sales_MA_4', 'Sales_MA_8', 'Sales_MA_12',\n","    'Sales_STD_4', 'Sales_STD_8', 'Sales_STD_12'\n","]\n","\n","def drop_lag_features(data, columns_to_drop):\n","    existing_cols = [col for col in columns_to_drop if col in data.columns]\n","    cleaned_data = data.drop(columns=existing_cols)\n","    print(f\"Dropped {len(existing_cols)} lag/MA columns: {existing_cols}\")\n","    return cleaned_data\n","\n","train_processed_clean = drop_lag_features(train_processed, lag_columns_to_drop)\n","test_processed_clean = drop_lag_features(test_processed, lag_columns_to_drop)\n","\n","# Log cleaning step\n","with mlflow.start_run(run_name=\"PatchTST_Cleaning\"):\n","    mlflow.log_param(\"columns_to_drop_count\", len(lag_columns_to_drop))\n","    mlflow.log_metric(\"original_train_rows\", train_processed.shape[0])\n","    mlflow.log_metric(\"final_train_rows\", train_processed_clean.shape[0])\n","\n","print(f\"Cleaned train shape: {train_processed_clean.shape}\")"],"id":"k6L3iX1HeCP7"},{"cell_type":"markdown","metadata":{"id":"r7-PyPmfeCP7"},"source":["### CELL 7: Prepare Time Series Data for PatchTST"],"id":"r7-PyPmfeCP7"},{"cell_type":"markdown","metadata":{"id":"mkeMOFpWeCP7"},"source":["Prepare time series data for PatchTST"],"id":"mkeMOFpWeCP7"},{"cell_type":"code","execution_count":8,"metadata":{"id":"XNXkGSoneCP7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751871398954,"user_tz":-240,"elapsed":202,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"983576ac-5980-4652-8667-8ff1e3ba2a9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train sequences: (55, 52)\n","Validation sequences: (22, 52)\n"]}],"source":["class TimeSeriesDataPreparation:\n","    def __init__(self, seq_len=52, pred_len=8, stride=1):\n","        self.seq_len = seq_len\n","        self.pred_len = pred_len\n","        self.stride = stride\n","        self.scalers = {}\n","\n","    def prepare_hierarchical_data(self, data, level='total'):\n","        data = data.copy()\n","        data['Date'] = pd.to_datetime(data['Date'])\n","        if level == 'total':\n","            agg_data = data.groupby('Date')['Weekly_Sales'].sum().reset_index().sort_values('Date')\n","            return agg_data\n","\n","    def create_sequences(self, data, target_col='Weekly_Sales'):\n","        sequences, targets = [], []\n","        values = data[target_col].values\n","        for i in range(0, len(values) - self.seq_len - self.pred_len + 1, self.stride):\n","            seq = values[i:i + self.seq_len]\n","            target = values[i + self.seq_len:i + self.seq_len + self.pred_len]\n","            sequences.append(seq)\n","            targets.append(target)\n","        return np.array(sequences), np.array(targets)\n","\n","data_prep = TimeSeriesDataPreparation(seq_len=52, pred_len=8, stride=1)\n","\n","total_sales_df = data_prep.prepare_hierarchical_data(train_processed_clean, level='total')\n","\n","# Train-validation split (80/20) based on date\n","validation_size = 0.2\n","split_idx = int(len(total_sales_df) * (1 - validation_size))\n","train_series_df = total_sales_df.iloc[:split_idx]\n","val_series_df = total_sales_df.iloc[split_idx - data_prep.seq_len:]  # keep overlap\n","\n","# Scale the data (fit on training only)\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","train_series_df['Scaled'] = scaler.fit_transform(train_series_df[['Weekly_Sales']])\n","val_series_df['Scaled'] = scaler.transform(val_series_df[['Weekly_Sales']])\n","\n","train_seqs, train_tgts = data_prep.create_sequences(train_series_df, target_col='Scaled')\n","val_seqs, val_tgts = data_prep.create_sequences(val_series_df, target_col='Scaled')\n","\n","print(f\"Train sequences: {train_seqs.shape}\")\n","print(f\"Validation sequences: {val_seqs.shape}\")"],"id":"XNXkGSoneCP7"},{"cell_type":"markdown","metadata":{"id":"5377mFGzeCP7"},"source":["### CELL 8: Define PatchTST Architecture"],"id":"5377mFGzeCP7"},{"cell_type":"markdown","metadata":{"id":"1kqJkBKdeCP7"},"source":["PatchTST Model Implementation (simplified)"],"id":"1kqJkBKdeCP7"},{"cell_type":"code","execution_count":9,"metadata":{"id":"QcMlYWKaeCP7","executionInfo":{"status":"ok","timestamp":1751871402566,"user_tz":-240,"elapsed":2,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}}},"outputs":[],"source":["class PatchTST(nn.Module):\n","    def __init__(self, seq_len, pred_len, n_features=1, patch_len=16, stride=16,\n","                 d_model=128, n_heads=8, num_layers=4, d_ff=256, dropout=0.1):\n","        super(PatchTST, self).__init__()\n","        self.seq_len = seq_len\n","        self.pred_len = pred_len\n","        self.n_features = n_features\n","        self.patch_len = patch_len\n","        self.stride = stride\n","        self.num_patches = ((seq_len - patch_len) // stride) + 1\n","        self.patch_embedding = nn.Linear(patch_len * n_features, d_model)\n","        self.position_embedding = nn.Parameter(torch.randn(1, self.num_patches, d_model))\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads,\n","                                                    dim_feedforward=d_ff, dropout=dropout,\n","                                                    activation='gelu')\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(self.num_patches * d_model, pred_len * n_features)\n","\n","    def forward(self, x):  # x: (batch, seq_len, n_features)\n","        b = x.size(0)\n","        # Create patches\n","        # (batch, n_features, seq_len)\n","        x = x.permute(0, 2, 1)\n","        patches = x.unfold(dimension=2, size=self.patch_len, step=self.stride)  # (b, n_feat, num_patches, patch_len)\n","        patches = patches.contiguous().view(b, self.n_features, self.num_patches, self.patch_len)\n","        patches = patches.permute(0, 2, 1, 3).contiguous().view(b, self.num_patches, -1)  # flatten\n","        tokens = self.patch_embedding(patches) + self.position_embedding  # (b, num_patches, d_model)\n","        tokens = tokens.permute(1, 0, 2)  # (num_patches, b, d_model)\n","        encoded = self.transformer(tokens)\n","        encoded = encoded.permute(1, 0, 2).contiguous().view(b, -1)\n","        out = self.fc(encoded).view(b, self.pred_len, self.n_features)\n","        return out"],"id":"QcMlYWKaeCP7"},{"cell_type":"markdown","metadata":{"id":"ZVpwTypueCP7"},"source":["### CELL 9: Prepare PyTorch Datasets & Loaders"],"id":"ZVpwTypueCP7"},{"cell_type":"markdown","metadata":{"id":"DIsQDCoKeCP8"},"source":["Build Dataset and DataLoader for training"],"id":"DIsQDCoKeCP8"},{"cell_type":"code","execution_count":10,"metadata":{"id":"fBMO318FeCP8","executionInfo":{"status":"ok","timestamp":1751871404931,"user_tz":-240,"elapsed":25,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}}},"outputs":[],"source":["class SequenceDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.x = torch.from_numpy(sequences).float().unsqueeze(-1)  # (N, seq_len, 1)\n","        self.y = torch.from_numpy(targets).float().unsqueeze(-1)    # (N, pred_len, 1)\n","    def __len__(self):\n","        return len(self.x)\n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_loader = DataLoader(SequenceDataset(train_seqs, train_tgts), batch_size=64, shuffle=True)\n","val_loader = DataLoader(SequenceDataset(val_seqs, val_tgts), batch_size=64, shuffle=False)"],"id":"fBMO318FeCP8"},{"cell_type":"markdown","metadata":{"id":"Qf7nMeZMeCP8"},"source":["### CELL 10: Train PatchTST Model"],"id":"Qf7nMeZMeCP8"},{"cell_type":"markdown","metadata":{"id":"_1r8aeY1eCP8"},"source":["Training loop with MLflow tracking"],"id":"_1r8aeY1eCP8"},{"cell_type":"code","execution_count":11,"metadata":{"id":"4HxgiYR9eCP8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751871716784,"user_tz":-240,"elapsed":309175,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"927b89ba-68f6-4b5d-f2eb-668a5f449b76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 01/50 | Train Loss: 1.2394 | Val Loss: 0.6575\n","Epoch 02/50 | Train Loss: 1.3869 | Val Loss: 0.2548\n","Epoch 03/50 | Train Loss: 0.9273 | Val Loss: 0.1544\n","Epoch 04/50 | Train Loss: 0.7795 | Val Loss: 0.2077\n","Epoch 05/50 | Train Loss: 0.7958 | Val Loss: 0.2379\n","Epoch 06/50 | Train Loss: 0.7432 | Val Loss: 0.1914\n","Epoch 07/50 | Train Loss: 0.6203 | Val Loss: 0.1375\n","Epoch 08/50 | Train Loss: 0.5035 | Val Loss: 0.1570\n","Epoch 09/50 | Train Loss: 0.4478 | Val Loss: 0.1972\n","Epoch 10/50 | Train Loss: 0.4187 | Val Loss: 0.2171\n","Epoch 11/50 | Train Loss: 0.3734 | Val Loss: 0.2008\n","Epoch 12/50 | Train Loss: 0.3223 | Val Loss: 0.1862\n","Epoch 13/50 | Train Loss: 0.2948 | Val Loss: 0.2057\n","Epoch 14/50 | Train Loss: 0.2630 | Val Loss: 0.2107\n","Epoch 15/50 | Train Loss: 0.2606 | Val Loss: 0.1944\n","Epoch 16/50 | Train Loss: 0.2412 | Val Loss: 0.1759\n","Epoch 17/50 | Train Loss: 0.2265 | Val Loss: 0.1563\n","Epoch 18/50 | Train Loss: 0.2138 | Val Loss: 0.1400\n","Epoch 19/50 | Train Loss: 0.1871 | Val Loss: 0.1358\n","Epoch 20/50 | Train Loss: 0.1735 | Val Loss: 0.1372\n","Epoch 21/50 | Train Loss: 0.1671 | Val Loss: 0.1358\n","Epoch 22/50 | Train Loss: 0.1708 | Val Loss: 0.1301\n","Epoch 23/50 | Train Loss: 0.1516 | Val Loss: 0.1243\n","Epoch 24/50 | Train Loss: 0.1504 | Val Loss: 0.1192\n","Epoch 25/50 | Train Loss: 0.1379 | Val Loss: 0.1186\n","Epoch 26/50 | Train Loss: 0.1343 | Val Loss: 0.1241\n","Epoch 27/50 | Train Loss: 0.1287 | Val Loss: 0.1303\n","Epoch 28/50 | Train Loss: 0.1200 | Val Loss: 0.1347\n","Epoch 29/50 | Train Loss: 0.1221 | Val Loss: 0.1260\n","Epoch 30/50 | Train Loss: 0.1163 | Val Loss: 0.1251\n","Epoch 31/50 | Train Loss: 0.1059 | Val Loss: 0.1360\n","Epoch 32/50 | Train Loss: 0.1076 | Val Loss: 0.1364\n","Epoch 33/50 | Train Loss: 0.0975 | Val Loss: 0.1350\n","Epoch 34/50 | Train Loss: 0.0888 | Val Loss: 0.1334\n","Epoch 35/50 | Train Loss: 0.0855 | Val Loss: 0.1337\n","Epoch 36/50 | Train Loss: 0.0887 | Val Loss: 0.1357\n","Epoch 37/50 | Train Loss: 0.0829 | Val Loss: 0.1347\n","Epoch 38/50 | Train Loss: 0.0797 | Val Loss: 0.1334\n","Epoch 39/50 | Train Loss: 0.0788 | Val Loss: 0.1306\n","Epoch 40/50 | Train Loss: 0.0778 | Val Loss: 0.1283\n","Epoch 41/50 | Train Loss: 0.0836 | Val Loss: 0.1259\n","Epoch 42/50 | Train Loss: 0.0781 | Val Loss: 0.1240\n","Epoch 43/50 | Train Loss: 0.0765 | Val Loss: 0.1229\n","Epoch 44/50 | Train Loss: 0.0833 | Val Loss: 0.1228\n","Epoch 45/50 | Train Loss: 0.0749 | Val Loss: 0.1228\n","Epoch 46/50 | Train Loss: 0.0741 | Val Loss: 0.1231\n","Epoch 47/50 | Train Loss: 0.0785 | Val Loss: 0.1239\n","Epoch 48/50 | Train Loss: 0.0743 | Val Loss: 0.1245\n","Epoch 49/50 | Train Loss: 0.0783 | Val Loss: 0.1247\n","Epoch 50/50 | Train Loss: 0.0769 | Val Loss: 0.1249\n","Training complete. Best Val Loss: 0.1186\n","🏃 View run PatchTST_Training at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9/runs/7f9bb2933baf4aa5b4369434320ed91a\n","🧪 View experiment at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9\n"]}],"source":["with mlflow.start_run(run_name=\"PatchTST_Training\"):\n","    # Hyperparameters\n","    seq_len = data_prep.seq_len\n","    pred_len = data_prep.pred_len\n","    model_params = {\n","        'patch_len': 16,\n","        'stride': 16,\n","        'd_model': 128,\n","        'n_heads': 8,\n","        'num_layers': 4,\n","        'd_ff': 256,\n","        'dropout': 0.1\n","    }\n","\n","    # Log parameters\n","    mlflow.log_params(model_params)\n","    mlflow.log_param('seq_len', seq_len)\n","    mlflow.log_param('pred_len', pred_len)\n","\n","    model = PatchTST(seq_len=seq_len, pred_len=pred_len, **model_params).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n","\n","    best_val_loss = float('inf')\n","    epochs = 50\n","\n","    for epoch in range(1, epochs + 1):\n","        model.train()\n","        train_losses = []\n","        for xb, yb in train_loader:\n","            xb, yb = xb.to(device), yb.to(device)\n","            optimizer.zero_grad()\n","            pred = model(xb)\n","            loss = criterion(pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","\n","        model.eval()\n","        val_losses = []\n","        with torch.no_grad():\n","            for xb, yb in val_loader:\n","                xb, yb = xb.to(device), yb.to(device)\n","                pred = model(xb)\n","                loss = criterion(pred, yb)\n","                val_losses.append(loss.item())\n","\n","        train_loss = np.mean(train_losses)\n","        val_loss = np.mean(val_losses)\n","        scheduler.step(val_loss)\n","\n","        mlflow.log_metric('train_loss', train_loss, step=epoch)\n","        mlflow.log_metric('val_loss', val_loss, step=epoch)\n","\n","        print(f\"Epoch {epoch:02d}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n","\n","        # Save best model\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), 'patchtst_best.pth')\n","            mlflow.log_artifact('patchtst_best.pth')\n","\n","    print(f\"Training complete. Best Val Loss: {best_val_loss:.4f}\")\n","    mlflow.log_metric('best_val_loss', best_val_loss)"],"id":"4HxgiYR9eCP8"},{"cell_type":"markdown","metadata":{"id":"yYk3XnyzeCP8"},"source":["### CELL 11: Hyperparameter Tuning"],"id":"yYk3XnyzeCP8"},{"cell_type":"markdown","metadata":{"id":"ujtcQZgCeCP8"},"source":["Simple grid search over a handful of PatchTST hyper-parameters to find a\n","better configuration.  Runs are deliberately kept short (epochs=30) so that\n","the search finishes in Colab.  All trials are logged to MLflow."],"id":"ujtcQZgCeCP8"},{"cell_type":"code","execution_count":16,"metadata":{"id":"lMZIVT1_eCP8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751875127538,"user_tz":-240,"elapsed":633708,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"6d415293-39b0-4ee1-d4f5-60dd8ee53cdb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Trial 1: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4092, RMSE=0.4780\n","\n","Trial 2: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4054, RMSE=0.4729\n","\n","Trial 3: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3884, RMSE=0.4673\n","\n","Trial 4: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3974, RMSE=0.4787\n","\n","Trial 5: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3785, RMSE=0.4557\n","\n","Trial 6: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4006, RMSE=0.4910\n","\n","Trial 7: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2825, RMSE=0.3510\n","\n","Trial 8: {'patch_len': 8, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3733, RMSE=0.4623\n","\n","Trial 9: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.6498, RMSE=0.7536\n","\n","Trial 10: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.5099, RMSE=0.6666\n","\n","Trial 11: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.5885, RMSE=0.7002\n","\n","Trial 12: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.5455, RMSE=0.6322\n","\n","Trial 13: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3843, RMSE=0.4640\n","\n","Trial 14: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4484, RMSE=0.5289\n","\n","Trial 15: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3956, RMSE=0.5068\n","\n","Trial 16: {'patch_len': 8, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.6110, RMSE=0.7055\n","\n","Trial 17: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3371, RMSE=0.4119\n","\n","Trial 18: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3235, RMSE=0.3935\n","\n","Trial 19: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2562, RMSE=0.3154\n","\n","Trial 20: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.2923, RMSE=0.3541\n","\n","Trial 21: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3211, RMSE=0.3970\n","\n","Trial 22: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3253, RMSE=0.4035\n","\n","Trial 23: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3352, RMSE=0.4099\n","\n","Trial 24: {'patch_len': 8, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.2500, RMSE=0.3179\n","\n","Trial 25: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4131, RMSE=0.5036\n","\n","Trial 26: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3964, RMSE=0.4755\n","\n","Trial 27: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3779, RMSE=0.4719\n","\n","Trial 28: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3725, RMSE=0.4606\n","\n","Trial 29: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4547, RMSE=0.5368\n","\n","Trial 30: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4104, RMSE=0.5019\n","\n","Trial 31: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4358, RMSE=0.5109\n","\n","Trial 32: {'patch_len': 8, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.5152, RMSE=0.6137\n","\n","Trial 33: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4366, RMSE=0.5234\n","\n","Trial 34: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4435, RMSE=0.5266\n","\n","Trial 35: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4592, RMSE=0.5691\n","\n","Trial 36: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3592, RMSE=0.4267\n","\n","Trial 37: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4104, RMSE=0.4846\n","\n","Trial 38: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3896, RMSE=0.4689\n","\n","Trial 39: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3822, RMSE=0.4713\n","\n","Trial 40: {'patch_len': 16, 'stride': 4, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3123, RMSE=0.3908\n","\n","Trial 41: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4958, RMSE=0.5792\n","\n","Trial 42: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3911, RMSE=0.4975\n","\n","Trial 43: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4703, RMSE=0.5643\n","\n","Trial 44: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.2920, RMSE=0.3692\n","\n","Trial 45: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4362, RMSE=0.5172\n","\n","Trial 46: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4169, RMSE=0.5387\n","\n","Trial 47: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4153, RMSE=0.5017\n","\n","Trial 48: {'patch_len': 16, 'stride': 4, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4100, RMSE=0.4986\n","\n","Trial 49: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2820, RMSE=0.3568\n","\n","Trial 50: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3549, RMSE=0.4238\n","\n","Trial 51: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3511, RMSE=0.4253\n","\n","Trial 52: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3534, RMSE=0.4396\n","\n","Trial 53: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2262, RMSE=0.2905\n","\n","Trial 54: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.2557, RMSE=0.3241\n","\n","Trial 55: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2470, RMSE=0.3202\n","\n","Trial 56: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3579, RMSE=0.4391\n","\n","Trial 57: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.4627, RMSE=0.5503\n","\n","Trial 58: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3498, RMSE=0.4264\n","\n","Trial 59: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3768, RMSE=0.4607\n","\n","Trial 60: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4099, RMSE=0.4843\n","\n","Trial 61: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3526, RMSE=0.4339\n","\n","Trial 62: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3628, RMSE=0.4442\n","\n","Trial 63: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2975, RMSE=0.3734\n","\n","Trial 64: {'patch_len': 16, 'stride': 8, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3459, RMSE=0.4223\n","\n","Trial 65: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.2770, RMSE=0.3559\n","\n","Trial 66: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3402, RMSE=0.4129\n","\n","Trial 67: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3402, RMSE=0.4171\n","\n","Trial 68: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3968, RMSE=0.4620\n","\n","Trial 69: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3284, RMSE=0.4041\n","\n","Trial 70: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.2930, RMSE=0.3656\n","\n","Trial 71: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3127, RMSE=0.3978\n","\n","Trial 72: {'patch_len': 16, 'stride': 16, 'd_model': 64, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.2474, RMSE=0.3158\n","\n","Trial 73: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3503, RMSE=0.4378\n","\n","Trial 74: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 4, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.3764, RMSE=0.4678\n","\n","Trial 75: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3350, RMSE=0.4211\n","\n","Trial 76: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 4, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4403, RMSE=0.5212\n","\n","Trial 77: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3608, RMSE=0.4258\n","\n","Trial 78: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 8, 'num_layers': 3, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4773, RMSE=0.5617\n","\n","Trial 79: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 128, 'dropout': 0.1}\n","MAE=0.3386, RMSE=0.4147\n","\n","Trial 80: {'patch_len': 16, 'stride': 16, 'd_model': 128, 'n_heads': 8, 'num_layers': 4, 'd_ff': 256, 'dropout': 0.1}\n","MAE=0.4677, RMSE=0.5567\n","🏃 View run PatchTST_Hyperparameter_Search at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9/runs/5fa79a19ee3c448692dce3dc64586dc2\n","🧪 View experiment at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9\n","\n","Best params after search: {'patch_len': 16, 'stride': 8, 'd_model': 64, 'n_heads': 8, 'num_layers': 3, 'd_ff': 128, 'dropout': 0.1}, MAE=0.2262\n"]}],"source":["from itertools import product\n","\n","param_grid = {\n","    'patch_len': [8, 16],\n","    'stride': [4, 8, 16],\n","    'd_model': [64, 128],\n","    'n_heads': [4, 8],\n","    'num_layers': [3, 4],\n","    'd_ff': [128, 256],\n","    'dropout': [0.1],\n","}\n","\n","best_params = None\n","best_val_mae = float('inf')\n","\n","with mlflow.start_run(run_name=\"PatchTST_Hyperparameter_Search\"):\n","    trial_id = 0\n","    for patch_len, stride, d_model, n_heads, num_layers, d_ff, dropout in product(\n","        param_grid['patch_len'],\n","        param_grid['stride'],\n","        param_grid['d_model'],\n","        param_grid['n_heads'],\n","        param_grid['num_layers'],\n","        param_grid['d_ff'],\n","        param_grid['dropout']\n","    ):\n","        # Skip invalid combinations\n","        if stride > patch_len:\n","            continue\n","\n","        trial_params = {\n","            'patch_len': patch_len,\n","            'stride': stride,\n","            'd_model': d_model,\n","            'n_heads': n_heads,\n","            'num_layers': num_layers,\n","            'd_ff': d_ff,\n","            'dropout': dropout,\n","        }\n","\n","        trial_id += 1\n","        print(f\"\\nTrial {trial_id}: {trial_params}\")\n","        mlflow.log_params({f\"trial{trial_id}_{k}\": v for k, v in trial_params.items()})\n","\n","        # Build model\n","        model_tune = PatchTST(seq_len=data_prep.seq_len, pred_len=data_prep.pred_len, **trial_params).to(device)\n","        criterion = nn.L1Loss()  # MAE\n","        optimizer = torch.optim.Adam(model_tune.parameters(), lr=1e-3)\n","\n","        # Short training\n","        epochs_search = 30\n","        for ep in range(epochs_search):\n","            model_tune.train()\n","            for xb, yb in train_loader:\n","                xb, yb = xb.to(device), yb.to(device)\n","                opt = torch.optim.Adam(model_tune.parameters(), lr=1e-3)\n","                opt.zero_grad()\n","                y_pred = model_tune(xb)\n","                loss = criterion(y_pred, yb)\n","                loss.backward()\n","                opt.step()\n","\n","        # Validate\n","        model_tune.eval()\n","        val_preds, val_trues = [], []\n","        with torch.no_grad():\n","            for xb, yb in val_loader:\n","                xb = xb.to(device)\n","                pred = model_tune(xb).cpu()\n","                val_preds.append(pred)\n","                val_trues.append(yb)\n","\n","        val_preds = torch.cat(val_preds, 0).numpy().flatten()\n","        val_trues = torch.cat(val_trues, 0).numpy().flatten()\n","        mae_val = mean_absolute_error(val_trues, val_preds)\n","        rmse_val = np.sqrt(mean_squared_error(val_trues, val_preds))\n","\n","        print(f\"MAE={mae_val:.4f}, RMSE={rmse_val:.4f}\")\n","        mlflow.log_metric(f\"trial{trial_id}_mae\", mae_val)\n","        mlflow.log_metric(f\"trial{trial_id}_rmse\", rmse_val)\n","\n","        if mae_val < best_val_mae:\n","            best_val_mae = mae_val\n","            best_params = trial_params\n","            mlflow.log_metric(\"best_val_mae\", best_val_mae)\n","\n","    # ✅ After all trials, log best params (safe logging)\n","    if best_params:\n","        safe_params = {f\"best_{k}\": str(v) for k, v in best_params.items()}\n","        mlflow.log_params(safe_params)\n","\n","print(f\"\\nBest params after search: {best_params}, MAE={best_val_mae:.4f}\")\n"],"id":"lMZIVT1_eCP8"},{"cell_type":"markdown","metadata":{"id":"FZW4efV8eCP8"},"source":["### CELL 12: Train Final PatchTST on Full Data"],"id":"FZW4efV8eCP8"},{"cell_type":"markdown","metadata":{"id":"M-pg3j97eCP8"},"source":["Re-prepare the *full* training set (train + previous validation) and fit the\n","best-configuration PatchTST for longer.  We fit a fresh StandardScaler over\n","the entire series to avoid data leakage."],"id":"M-pg3j97eCP8"},{"cell_type":"code","execution_count":17,"metadata":{"id":"E0N4tMV1eCP9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751875674533,"user_tz":-240,"elapsed":447150,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"ad6c2e86-fc4f-4061-d279-599ae9cb573d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150 - Loss: 1.1454\n","Epoch 25/150 - Loss: 0.1924\n","Epoch 50/150 - Loss: 0.0793\n","Epoch 75/150 - Loss: 0.0579\n","Epoch 100/150 - Loss: 0.0459\n","Epoch 125/150 - Loss: 0.0453\n","Epoch 150/150 - Loss: 0.0390\n","🏃 View run PatchTST_Final_Model at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9/runs/c2e38d6b3da147aca399b08ab06dbb7c\n","🧪 View experiment at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9\n"]}],"source":["full_series_df = total_sales_df.copy()\n","\n","final_scaler = StandardScaler()\n","full_series_df['Scaled'] = final_scaler.fit_transform(full_series_df[['Weekly_Sales']])\n","\n","full_seqs, full_tgts = data_prep.create_sequences(full_series_df, target_col='Scaled')\n","full_loader = DataLoader(SequenceDataset(full_seqs, full_tgts), batch_size=64, shuffle=True)\n","\n","final_epochs = 150\n","with mlflow.start_run(run_name=\"PatchTST_Final_Model\"):\n","    mlflow.log_params(best_params)\n","    mlflow.log_param(\"epochs\", final_epochs)\n","\n","    final_model = PatchTST(seq_len=data_prep.seq_len, pred_len=data_prep.pred_len, **best_params).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(final_model.parameters(), lr=1e-3)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5, verbose=True)\n","\n","    for ep in range(1, final_epochs + 1):\n","        final_model.train()\n","        losses = []\n","        for xb, yb in full_loader:\n","            xb, yb = xb.to(device), yb.to(device)\n","            optimizer.zero_grad()\n","            pred = final_model(xb)\n","            loss = criterion(pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","            losses.append(loss.item())\n","        epoch_loss = np.mean(losses)\n","        scheduler.step(epoch_loss)\n","        mlflow.log_metric('train_loss', epoch_loss, step=ep)\n","        if ep % 25 == 0 or ep == 1:\n","            print(f\"Epoch {ep}/{final_epochs} - Loss: {epoch_loss:.4f}\")\n","\n","    torch.save(final_model.state_dict(), 'patchtst_final.pth')\n","    mlflow.log_artifact('patchtst_final.pth')\n","    joblib.dump(final_scaler, 'patchtst_final_scaler.pkl')\n","    mlflow.log_artifact('patchtst_final_scaler.pkl')"],"id":"E0N4tMV1eCP9"},{"cell_type":"markdown","metadata":{"id":"FvXJyqV9eCP9"},"source":["### CELL 13: Store-Level PatchTST Models (Top 5 Stores)"],"id":"FvXJyqV9eCP9"},{"cell_type":"markdown","metadata":{"id":"8vsIvRlqeCP9"},"source":["Train smaller PatchTST models for the top-5 stores to better capture local\n","patterns."],"id":"8vsIvRlqeCP9"},{"cell_type":"code","execution_count":18,"metadata":{"id":"m_TKk0ifeCQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751876722435,"user_tz":-240,"elapsed":16085,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"c2adf570-f585-490a-b82f-761e742b9b0e"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /egval20/ML-Final.mlflow/api/2.0/mlflow/runs/create\n"]},{"output_type":"stream","name":"stdout","text":["Top 5 stores: [20, 4, 14, 13, 2]\n","\n","Training model for Store 20\n","  Store 20 Epoch 20 MAE=0.3386\n","  Store 20 Epoch 40 MAE=0.3184\n","\n","Training model for Store 4\n","  Store 4 Epoch 20 MAE=0.2896\n","  Store 4 Epoch 40 MAE=0.2344\n","\n","Training model for Store 14\n","  Store 14 Epoch 20 MAE=0.9341\n","  Store 14 Epoch 40 MAE=0.8775\n","\n","Training model for Store 13\n","  Store 13 Epoch 20 MAE=0.3031\n","  Store 13 Epoch 40 MAE=0.2526\n","\n","Training model for Store 2\n","  Store 2 Epoch 20 MAE=0.3539\n","  Store 2 Epoch 40 MAE=0.3882\n","🏃 View run PatchTST_Store_Models at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9/runs/7710f4fc7c674578b489f273447506be\n","🧪 View experiment at: https://dagshub.com/egval20/ML-Final.mlflow/#/experiments/9\n"]}],"source":["store_sales = train_processed_clean.groupby('Store')['Weekly_Sales'].sum().nlargest(5)\n","\n","top_stores = store_sales.index.tolist()\n","print(f\"Top 5 stores: {top_stores}\")\n","\n","store_models = {}\n","store_metrics = {}\n","\n","with mlflow.start_run(run_name=\"PatchTST_Store_Models\"):\n","    mlflow.log_param(\"top_stores\", top_stores)\n","    for store in top_stores:\n","        print(f\"\\nTraining model for Store {store}\")\n","        store_df = train_processed_clean[train_processed_clean['Store'] == store]\n","        store_series = data_prep.prepare_hierarchical_data(store_df, level='total')\n","\n","        # Use its own scaler to avoid scale mismatch\n","        s_scaler = StandardScaler()\n","        store_series['Scaled'] = s_scaler.fit_transform(store_series[['Weekly_Sales']])\n","\n","        s_seqs, s_tgts = data_prep.create_sequences(store_series, target_col='Scaled')\n","        if len(s_seqs) < 10:\n","            print(\"  Skipping – not enough data after sequencing.\")\n","            continue\n","        s_train_len = int(len(s_seqs) * 0.8)\n","        s_train_ds = SequenceDataset(s_seqs[:s_train_len], s_tgts[:s_train_len])\n","        s_val_ds   = SequenceDataset(s_seqs[s_train_len:], s_tgts[s_train_len:])\n","        s_train_loader = DataLoader(s_train_ds, batch_size=32, shuffle=True)\n","        s_val_loader   = DataLoader(s_val_ds, batch_size=32, shuffle=False)\n","\n","        s_model = PatchTST(seq_len=data_prep.seq_len, pred_len=data_prep.pred_len, **best_params).to(device)\n","        crit = nn.L1Loss()\n","        opt  = torch.optim.Adam(s_model.parameters(), lr=5e-4)\n","\n","        best_s_val_mae = float('inf')\n","        for ep in range(1, 60):\n","            s_model.train()\n","            for xb, yb in s_train_loader:\n","                xb, yb = xb.to(device), yb.to(device)\n","                opt.zero_grad()\n","                pred = s_model(xb)\n","                loss = crit(pred, yb)\n","                loss.backward()\n","                opt.step()\n","\n","            # quick val\n","            s_model.eval()\n","            preds, trues = [], []\n","            with torch.no_grad():\n","                for xb, yb in s_val_loader:\n","                    xb = xb.to(device)\n","                    p = s_model(xb).cpu()\n","                    preds.append(p)\n","                    trues.append(yb)\n","            preds = torch.cat(preds, 0).numpy().flatten()\n","            trues = torch.cat(trues, 0).numpy().flatten()\n","            mae_s = mean_absolute_error(trues, preds)\n","            if mae_s < best_s_val_mae:\n","                best_s_val_mae = mae_s\n","                torch.save(s_model.state_dict(), f'patchtst_store_{store}.pth')\n","            if ep % 20 == 0:\n","                print(f\"  Store {store} Epoch {ep} MAE={mae_s:.4f}\")\n","\n","        mlflow.log_metric(f\"store_{store}_best_mae\", best_s_val_mae)\n","        store_models[store] = {\n","            'model_path': f'patchtst_store_{store}.pth',\n","            'scaler': s_scaler\n","        }\n","\n","joblib.dump(store_models, 'patchtst_store_models.pkl')\n","mlflow.log_artifact('patchtst_store_models.pkl')"],"id":"m_TKk0ifeCQA"},{"cell_type":"markdown","metadata":{"id":"btGbw47yeCQA"},"source":["### CELL 14: Final Forecast for Kaggle Submission (using Final Model)"],"id":"btGbw47yeCQA"},{"cell_type":"markdown","metadata":{"id":"Gfd6MQ-ZeCQA"},"source":["Produce predictions for the public test set using the final aggregated model."],"id":"Gfd6MQ-ZeCQA"},{"cell_type":"code","execution_count":19,"metadata":{"id":"vQoBZotyeCQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751876870343,"user_tz":-240,"elapsed":13939,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"47deeb36-0a9c-4385-8df3-0e426d8d996d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Submission file saved – shape: (115064, 2)\n"]}],"source":["# Reload final model & scaler\n","final_model_loaded = PatchTST(seq_len=data_prep.seq_len, pred_len=data_prep.pred_len, **best_params).to(device)\n","final_model_loaded.load_state_dict(torch.load('patchtst_final.pth', map_location=device))\n","final_model_loaded.eval()\n","\n","# Prepare full (train + test) series scaled by final_scaler\n","full_series_all = pd.concat([train_processed_clean, test_processed_clean])\n","full_total_series = data_prep.prepare_hierarchical_data(full_series_all, level='total')\n","full_total_series['Scaled'] = final_scaler.transform(full_total_series[['Weekly_Sales']])\n","\n","test_start_idx = len(total_sales_df)\n","num_test_weeks = len(test_raw['Date'].unique())\n","\n","init_input = full_total_series['Scaled'].values[test_start_idx - data_prep.seq_len:test_start_idx]\n","cur_inp = torch.from_numpy(init_input).float().view(1, -1, 1).to(device)\n","\n","scaled_preds = []\n","with torch.no_grad():\n","    for i in range(0, num_test_weeks, data_prep.pred_len):\n","        pred = final_model_loaded(cur_inp)\n","        pred_np = pred.cpu().numpy().flatten()\n","        scaled_preds.extend(pred_np)\n","        # slide window\n","        cur_inp = torch.from_numpy(\n","            np.concatenate([cur_inp.cpu().numpy().flatten()[data_prep.pred_len:], pred_np])\n","        ).float().view(1, -1, 1).to(device)\n","\n","scaled_preds = scaled_preds[:num_test_weeks]\n","final_preds = final_scaler.inverse_transform(np.array(scaled_preds).reshape(-1, 1)).flatten()\n","\n","# Distribute to store / dept (same simple proportion method)\n","hist_props = train_processed_clean.groupby(['Store', 'Dept'])['Weekly_Sales'].sum()\n","hist_props = hist_props / hist_props.sum()\n","\n","submission_rows = []\n","unique_dates = list(test_raw.sort_values('Date')['Date'].unique())\n","for idx, row in test_raw.iterrows():\n","    store, dept, date = row['Store'], row['Dept'], row['Date']\n","    week_idx = unique_dates.index(date)\n","    prop = hist_props.get((store, dept), 1.0 / len(hist_props))\n","    submission_rows.append({\n","        'Id': f\"{store}_{dept}_{date}\",\n","        'Weekly_Sales': max(0, final_preds[week_idx] * prop)\n","    })\n","\n","submission_df = pd.DataFrame(submission_rows)\n","submission_df.to_csv('patchtst_submission.csv', index=False)\n","print(f\"Submission file saved – shape: {submission_df.shape}\")\n","mlflow.log_artifact('patchtst_submission.csv')"],"id":"vQoBZotyeCQA"},{"cell_type":"markdown","metadata":{"id":"Y8E-vWoHeCQA"},"source":["### CELL 15: Comprehensive Summary"],"id":"Y8E-vWoHeCQA"},{"cell_type":"code","execution_count":20,"metadata":{"id":"FktyBmYheCQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751877244460,"user_tz":-240,"elapsed":47,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"c779622e-ef11-433f-af64-2c49adba42d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","PATCHTST IMPLEMENTATION COMPLETE\n","============================================================\n","\n","Best Validation MAE after search: 0.2262\n","Final training epochs: 150\n","Top-5 store models trained: 5\n","Submission file: patchtst_submission.csv\n","All experiments, models & artifacts logged to MLflow\n","============================================================\n"]}],"source":["print(\"\\n\" + \"=\"*60)\n","print(\"PATCHTST IMPLEMENTATION COMPLETE\")\n","print(\"=\"*60)\n","print(f\"\\nBest Validation MAE after search: {best_val_mae:.4f}\")\n","print(f\"Final training epochs: {final_epochs}\")\n","print(f\"Top-5 store models trained: {len(store_models)}\")\n","print(\"Submission file: patchtst_submission.csv\")\n","print(\"All experiments, models & artifacts logged to MLflow\")\n","print(\"=\"*60)"],"id":"FktyBmYheCQA"},{"cell_type":"markdown","metadata":{"id":"6UR1cQeCeCQA"},"source":["Use the trained model to predict on the test period"],"id":"6UR1cQeCeCQA"},{"cell_type":"code","execution_count":21,"metadata":{"id":"C1lRrlIueCQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751877979741,"user_tz":-240,"elapsed":729838,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"3643f7e6-d856-43c6-aa94-4e8a4ed14baa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Submission saved! Shape: (115064, 2)\n"]}],"source":["# Reload best model\n","best_model = PatchTST(seq_len=data_prep.seq_len, pred_len=data_prep.pred_len, **model_params).to(device)\n","best_model.load_state_dict(torch.load('patchtst_best.pth', map_location=device))\n","best_model.eval()\n","\n","# Create full series (train + test) for iterative forecasting\n","full_series_df = pd.concat([train_processed_clean, test_processed_clean])\n","full_sales_df = data_prep.prepare_hierarchical_data(full_series_df, level='total')\n","full_sales_df['Scaled'] = scaler.transform(full_sales_df[['Weekly_Sales']])\n","\n","# Dates\n","train_dates = total_sales_df['Date']\n","full_dates = full_sales_df['Date']\n","\n","test_start_idx = len(total_sales_df)\n","\n","test_weeks = len(test_raw['Date'].unique())\n","\n","# Prepare initial input (last seq_len from training)\n","input_seq = full_sales_df['Scaled'].values[test_start_idx - data_prep.seq_len:test_start_idx]\n","current_input = torch.from_numpy(input_seq).float().view(1, -1, 1).to(device)\n","\n","predictions_scaled = []\n","with torch.no_grad():\n","    for i in range(0, test_weeks, data_prep.pred_len):\n","        pred = best_model(current_input)\n","        pred_np = pred.cpu().numpy().flatten()\n","        predictions_scaled.extend(pred_np)\n","\n","        # Update the input sequence with new predictions\n","        new_input = np.concatenate([\n","            current_input.cpu().numpy().flatten()[data_prep.pred_len:],\n","            pred_np\n","        ])\n","        current_input = torch.from_numpy(new_input).float().view(1, -1, 1).to(device)\n","\n","# Trim to exact number of test weeks\n","predictions_scaled = predictions_scaled[:test_weeks]\n","\n","# Inverse transform predictions\n","predictions = scaler.inverse_transform(np.array(predictions_scaled).reshape(-1, 1)).flatten()\n","\n","# Distribute predictions to store-department combinations using historical proportions\n","historical_props = train_processed_clean.groupby(['Store', 'Dept'])['Weekly_Sales'].sum()\n","historical_props = historical_props / historical_props.sum()\n","\n","submission_rows = []\n","test_raw_sorted = test_raw.sort_values('Date')  # Ensure alignment\n","for idx, row in test_raw_sorted.iterrows():\n","    store, dept, date = row['Store'], row['Dept'], row['Date']\n","    week_idx = list(test_raw_sorted['Date'].unique()).index(date)  # 0-based index\n","    prop = historical_props.get((store, dept), 1.0 / len(test_raw_sorted))\n","    pred_sales = max(0, predictions[week_idx] * prop)\n","    submission_rows.append({'Id': f\"{store}_{dept}_{date}\", 'Weekly_Sales': pred_sales})\n","\n","submission_df = pd.DataFrame(submission_rows)\n","submission_df.to_csv('patchtst_submission.csv', index=False)\n","print(f\"Submission saved! Shape: {submission_df.shape}\")\n","\n","# Log submission\n","mlflow.log_artifact('patchtst_submission.csv')"],"id":"C1lRrlIueCQB"},{"cell_type":"markdown","metadata":{"id":"TZQNMjegeCQB"},"source":["### CELL 12: Summary & Next Steps"],"id":"TZQNMjegeCQB"},{"cell_type":"markdown","metadata":{"id":"eRwSDPdIeCQB"},"source":["Summary of PatchTST experiment"],"id":"eRwSDPdIeCQB"},{"cell_type":"code","execution_count":22,"metadata":{"id":"CyiYro5eeCQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751878314353,"user_tz":-240,"elapsed":8,"user":{"displayName":"lasha gorgodze","userId":"05279787268210699338"}},"outputId":"e7f76f0f-d494-4895-d0c9-919635030504"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","PATCHTST MODEL TRAINING SUMMARY\n","============================================================\n","Best Validation Loss: 0.1186\n","Total Train Sequences: 55\n","Total Validation Sequences: 22\n","Submission file: patchtst_submission.csv\n","All artifacts & metrics logged to MLflow\n","============================================================\n"]}],"source":["print(\"\\n\" + \"=\"*60)\n","print(\"PATCHTST MODEL TRAINING SUMMARY\")\n","print(\"=\"*60)\n","print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n","print(f\"Total Train Sequences: {train_seqs.shape[0]}\")\n","print(f\"Total Validation Sequences: {val_seqs.shape[0]}\")\n","print(\"Submission file: patchtst_submission.csv\")\n","print(\"All artifacts & metrics logged to MLflow\")\n","print(\"=\"*60)"],"id":"CyiYro5eeCQB"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ec521b6752c2406daa97a81b02565fa4":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_e1e16669daa84ac2b67f5632da2368be","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[32m⠇\u001b[0m Waiting for authorization\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span> Waiting for authorization\n</pre>\n"},"metadata":{}}]}},"e1e16669daa84ac2b67f5632da2368be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}